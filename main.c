/*
============================================================================
Compilation:
gcc -Wall <program>.c -o <program> $(pkg-config --cflags --libs gstreamer-1.0)
./run <file.mp4>
-----------
gcc -Wall main.c -o run $(pkg-config --cflags --libs gstreamer-1.0)

./run video3.mp4
-----------
gst-launch-1.0 filesrc location=video2.mp4 ! qtdemux name=demux demux. ! queue ! avdec_h264 ! videoconvert ! facedetect profile=haarcascade_frontalface_default.xml ! videoconvert ! ximagesink

-----------
Compiler options (automatically generated by pkg-config):
-I/usr/include/gstreamer-0.10 --option for gcc to find the header files
============================================================================
*/

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <gst/gst.h>
#include <glib.h>



GstElement *queue_aud;
GstElement *queue_img;
// #define DEFAULT_PROFILE "haarcascade_frontalface_default.xml"
// g_param_spec_string ("profile", "Profile",
// "Location of Haar cascade file to use for face detection",DEFAULT_PROFILE, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
int estado = 0;

/* --------------------------------------------------------------------- *
*  Bus message handler
* --------------------------------------------------------------------- */
static gboolean bus_call (GstBus     *bus, GstMessage *msg, gpointer data)
  {
	//procesamiento de los mensajes
    GMainLoop *loop = (GMainLoop *) data;
    char *src = GST_MESSAGE_SRC_NAME(msg);

    switch (GST_MESSAGE_TYPE (msg)) {

      case GST_MESSAGE_EOS:
      g_print ("\n..[bus].. (%s) :: End of stream\n", src);
      g_main_loop_quit (loop);
      break;

      case GST_MESSAGE_ERROR: {
        gchar  *debug;
        GError *error;

        gst_message_parse_error (msg, &error, &debug);
        g_free (debug);

        g_printerr ("\n..[bus].. (%s) :: Error: %s\n", src, error->message);
        g_error_free (error);

        estado = -1;  // error multimedia
        g_main_loop_quit (loop);
        break;
      }
      
      case GST_MESSAGE_ELEMENT:{
      
      /*ESCTRUCTURA DE MENSAJE DE FACEDETECT
      
      Se obtuvo el mensaje nº 361 del elemento «facedetect0» 
      (element): facedetect, 
      			timestamp=(guint64)7173833333, 
      			stream-time=(guint64)7173833333, 
      			running-time=(guint64)7173833333, 
      			duration=(guint64)33366667, 
      			faces=(structure)
      			{ 
      				"face\,\ x\=\(uint\)188\,\ y\=\(uint\)10\,\ width\=\(uint\)89\,\ height\=\(uint\)89\;"
      			};

      */
      
      
      const GstStructure *structure;
      const gchar *name;
      const GValue *value;
      const gchar *faces;
      const GValue *timestamp;
      const gchar *ts;
      
      	/* parse msg structure */
		structure = gst_message_get_structure(msg);
		name = gst_structure_get_name(structure);
		timestamp = gst_structure_get_value(structure,"timestamp");
		/* get structure of faces */
    	value = gst_structure_get_value (structure, "faces");
    	
      if (structure && strcmp(name,"facedetect") == 0) 
      {
        g_print ("\nbus... type: %s || name: %s",src,name);
        
        
        
        //g_print (" timestamp: %" G_GUINT64_FORMAT "\n", ts);
        ts = g_strdup_value_contents(timestamp);
        g_print("|| timestamp: %s",ts);
        
        faces = g_strdup_value_contents(value);
        g_print("\n|| faces: %s\n",faces);
       
        
        /* print msg structure names and type */
      //gint i;
      //for (i = 0; i < gst_structure_n_fields (structure); i++) 
      //{
      //  const gchar *n = gst_structure_nth_field_name (structure, i);
      //  GType type = gst_structure_get_field_type (structure, n);
      //  g_print ("\n-Name field, type: %s[%s]", n, g_type_name(type));
      //}
        
        
      }
        break;
        
      }

      default: {
        //g_print ("..[bus].. %15s :: %-15s\n", src, GST_MESSAGE_TYPE_NAME(msg));
        break;
      }
    }

    return TRUE;
  }



  /* --------------------------------------------------------------------- *
  *  Link dynamically created pads
  * --------------------------------------------------------------------- */
  static void on_pad_added (GstElement *element, GstPad *pad, gpointer data)
    {
      GstPad *sinkpad;

      gchar *name = gst_pad_get_name(pad);
      char *caps = gst_caps_to_string(gst_pad_get_current_caps(pad));

      g_print ("...Dynamic pad created: %s, capabilities: %s\n", name, caps);

      /* We can now link this pad with the appropriate decoder sink pad */

      if (g_str_has_prefix(caps, "audio")) {
        /* Audio dynamic pad: conect audio pipeline */
        sinkpad = gst_element_get_static_pad (queue_aud, "sink");

      } else if  (g_str_has_prefix(caps, "video")) {
        /* Audio dynamic pad: conect audio pipeline */
        sinkpad = gst_element_get_static_pad (queue_img, "sink");
      }

      if (sinkpad != NULL) {
        /* connect pads */
        gst_pad_link (pad, sinkpad);

        /* delete objects */
        gst_object_unref (sinkpad);
      }

    }


    int main(int argc, char *argv[]) {

      GMainLoop *loop;

      /* Check input arguments */
      if (argc != 2) {
        g_printerr ("Usage: %s <Mp4 filename>\n", argv[0]);
        return -1;  // error argumentos
      }


      //puts("GStreamer test - init!\n"); /* prints GStreamer test! */

      gst_init(&argc, &argv);  /* inits the GStreamer library */
      loop = g_main_loop_new (NULL, FALSE);



      /*
      * Create pipeline
      */

      /* Create pipeline */
      GstElement *pipeline = gst_pipeline_new ("mi_pipeline");
      /* Create elements */
      GstElement *source        = gst_element_factory_make("filesrc", "multimedia/video.mp4");
      GstElement *demuxer       = gst_element_factory_make("qtdemux", "mp4demux");
      GstElement *aud_dec       = gst_element_factory_make("faad", "auddec");
      GstElement *img_dec       = gst_element_factory_make("avdec_h264", "viddec");
      GstElement *vid_conv_in   = gst_element_factory_make("videoconvert", "videoconvert_in");
      GstElement *facedet       = gst_element_factory_make ("facedetect", "app_facedetect");
      GstElement *vid_conv_out  = gst_element_factory_make("videoconvert", "videoconvert_out");
      GstElement *aud_sink      = gst_element_factory_make("alsasink", "audio-output");
      GstElement *f_audioconv   = gst_element_factory_make("audioconvert", "audio_convert");
      GstElement *img_sink      = gst_element_factory_make("ximagesink", "image-output");

      queue_aud = gst_element_factory_make("queue", "queue-aud");
      queue_img = gst_element_factory_make("queue", "queue-img");



      /* Error checking */
      if ( !pipeline || !source     || !demuxer
        || !aud_dec  || !queue_aud  || !f_audioconv  || !aud_sink
        || !img_dec  || !queue_img  || !vid_conv_in  || !facedet || !vid_conv_out || !img_sink )
        {
          g_printerr ("One element could not be created. Exiting.\n");
          return -1;   // error multimedia
        }


        /*
        * Set up the pipeline
        */

        /* set the input filename to the source element */
        g_object_set (G_OBJECT (source), "location", argv[1], NULL);

        /* set the input filename for haar cascade file*/
        g_object_set(G_OBJECT(facedet), "profile","haarcascade_frontalface_default.xml",NULL);
        g_object_set(G_OBJECT(facedet), "updates",2,NULL);

        /* set the name for the demuxer element */
        g_object_set (G_OBJECT (demuxer), "name", "demux", NULL);


        /* Bus message handling */
        GstBus *bus = gst_pipeline_get_bus (GST_PIPELINE (pipeline));
        gst_bus_add_watch (bus, bus_call, loop);
        gst_object_unref (bus);



        /* Add elements to pipeline */
        gst_bin_add_many(GST_BIN(pipeline), source, demuxer, queue_aud, aud_dec, queue_img, img_dec, vid_conv_in, facedet, vid_conv_out, f_audioconv, aud_sink, img_sink, NULL);

        /* Link elements */

        /* note that the demuxer will be linked to the decoder dynamically.
        The reason is that Ogg may contain various streams (for example
        audio and video). The source pad(s) will be created at run time,
        by the demuxer when it detects the amount and nature of streams.
        Therefore we connect a callback function which will be executed
        when the "pad-added" is emitted.*/

        /* demuxer src pad is created dinamically -> needs to be linked later */
        gst_element_link (source, demuxer);
        gst_element_link_many(queue_aud, aud_dec, f_audioconv,  aud_sink, NULL);
        gst_element_link_many(queue_img, img_dec, vid_conv_in, facedet, vid_conv_out, img_sink, NULL);

        /* connect demuxer to the rest of the pipeline when pad is dinamycally added */
        g_signal_connect (demuxer, "pad-added", G_CALLBACK (on_pad_added), NULL);



        /*
        * Change of State
        */

        /* Set the pipeline to "playing" state*/
        //g_print("Play: %s\n", argv[1]);
        gst_element_set_state (pipeline, GST_STATE_PLAYING);

        /* Iterate */
        //g_print ("Run...\n");
        g_main_loop_run (loop);




        /*
        * END: clean up objects
        * Out of the main loop, clean up nicely
        */

        //g_print ("Returned, stopping playback\n");

        /* set state */
        gst_element_set_state (pipeline, GST_STATE_NULL);

        /*
        * Destroy objects (deallocate memory)
        * elements cannot be directly disposed while still in pipeline (or bin)
        */
        //g_print ("Deleting pipeline\n");
        gst_object_unref (GST_OBJECT (pipeline));


        //puts("\nGStreamer test - end!"); /* prints GStreamer test! */

        return estado;
      }
